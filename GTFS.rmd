---
title: "Bus_Data_Extraction"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
```

```{r}
# Load libraries
library(tidyverse)
library(jsonlite)
library(httr)
library(lubridate)
```

```{r}
# Obtain AT API Key
AT_key = "567bb1fb7ab64582905c7812648075e1"
# Get today's date
todays_date = as.character(Sys.Date())
# Saving folder structures
wd_main = getwd()
wd_rawdata = paste(wd_main, '/rawdata', sep = "")
wd_businfo = paste(wd_rawdata, '/businfo', sep = "")
wd_busarrivals = paste(wd_rawdata, '/busarrivals', sep = "")
```

```{r}
setwd(paste(wd_rawdata, '/businfo', sep = ""))
# Reading in bus static files 
stops = read.table("stops.txt", header = TRUE, sep = ",", quote = "")
stop_times = read.table("stop_times.txt", header = TRUE, sep = ",", quote = "")
trips = read.table("trips.txt", header = TRUE, sep = ",", quote = ",", fill = TRUE)
routes = read.table("routes.txt", header = TRUE, sep = ",", quote = "")
shapes = read.table("shapes.txt", header = TRUE, sep = ",", quote = "")
stop_times = stop_times %>% mutate(stop_code = substring(stop_id, 1, regexpr("-", stop_id)[1] - 1))
```

```{r}
# Grabbing live bus arrival data for current day
combined_feed <- tryCatch(
  GET('https://api.at.govt.nz/realtime/legacy/',
      accept_json(),
      add_headers('Ocp-Apim-Subscription-Key' = AT_key)),
  error=function(e) NULL)
vehicle <- tryCatch(
  GET('https://api.at.govt.nz/realtime/legacy/vehiclelocations',
      accept_json(),
      add_headers('Ocp-Apim-Subscription-Key' = AT_key)),
  error=function(e) NULL)
trip_updates <- tryCatch(
  GET('https://api.at.govt.nz/realtime/legacy/tripupdates',
      accept_json(),
      add_headers('Ocp-Apim-Subscription-Key' = AT_key)),
  error=function(e) NULL)
alerts <- tryCatch(
  GET('https://api.at.govt.nz/realtime/legacy/servicealerts',
      accept_json(),
      add_headers('Ocp-Apim-Subscription-Key' = AT_key)),
  error=function(e) NULL)
```


```{r}
# Saving data to JSON file
setwd(wd_busarrivals)
dir.create(todays_date)
setwd(paste(wd_busarrivals, paste('/', todays_date, sep = ""), sep = ""))
write_json(content(vehicle), paste('vehicle_', todays_date), pretty = TRUE)
write_json(content(combined_feed), paste('combined_', todays_date), pretty = TRUE)
write_json(content(trip_updates), paste('tripupdates_', todays_date), pretty = TRUE)
write_json(content(alerts), paste('alerts_', todays_date), pretty = TRUE)
```


```{r}

#Extract data is a function which takes in a JSON trip_updates file and a JSON alert files. The goal of this is to create 1 dataframe with all the required information for that given day

extract_data = function(trip_updates, alerts){
  
  #Json file strucutre, all the information is in the 2nd list within that 2nd list (I know confusing)
  trip_content =trip_updates[[2]][[2]]
  
  #Null check is a function that checks if a feature for an entity (individual buses) exist, if they don't we will replace that column as NA for that entity 
  null_check = function(x) if(is.null(x)) NA else x
  
  #
  trips = trips %>% filter(trip_id != "trip_id")
  
  #We will extract all the relevant columns from the trip_updates GTFS file.
  trip_data = as.data.frame(do.call(rbind, lapply(trip_content, 
                                                  function(x) c(null_check(x$trip_update$trip$trip_id[[1]][1]),
                                                                null_check(x$trip_update$trip$direction_id),
                                                                null_check(x$trip_update$trip$route_id),
                                                                null_check(x$trip_update$stop_time_update$stop_id),
                                                                null_check(x$trip_update$trip$schedule_relationship),
                                                                null_check(x$trip_update$delay), 
                                                                null_check(x$trip_update$stop_time_update$stop_sequence),
                                                                null_check(x$trip_update$stop_time_update$arrival$time),
                                                                null_check(x$trip_update$stop_time_update$arrival$delay),
                                                                null_check(x$trip_update$stop_time_update$departure$time),
                                                                null_check(x$trip_update$stop_time_update$departure$delay)
                                                  ))))
  
  #For some reason, my dataframe returns a dataframe of lists when we store it as JSON instead of reading directly from the website, code to sort this issue
  trip_data = as.data.frame(lapply(trip_data, unlist))
  
  # Setting column names
  colnames(trip_data) = c("trip_id", 
                          "direction_id", 
                          "route_id", 
                          "stop_id", 
                          "schedule_relationship", 
                          "delay", 
                          "stop_sequence", 
                          "act_arrival_time", 
                          "arrival_delay", 
                          "act_departure_time", 
                          "act_departure_delay")
  # Fixing stop sequence type
  trip_data$stop_sequence = as.integer(trip_data$stop_sequence)
  
  ## Now we want to sort out cancellation from the Alert dataset
  
  #Again with the trip_updates, JSON files are weird. The important information is stored in the 2nd item of a list, within that there's another list
  alert_contents = alerts[[2]][[2]]
  
  
  #Extract the relevent information we want from the alert dataset, Here we want the id and the effect (NO SERVICE, "MODIFIED SERVICE", etc)
  alert_data = as.data.frame(do.call(rbind, lapply(alert_contents, function(x) c(null_check(x$id), 
                                                                                           null_check(x$alert$effect), 
                                                                                           null_check(x$alert$header_text$translation[[1]]$text), 
                                                                                           null_check(x$alert$informed_entity[[1]]$trip$trip_id)))))
  
  
  #Again dataframe issue, just solving it here                                                                             
  alert_data = as.data.frame(lapply(alert_data, unlist))
  
  #Relevant column names
  
  colnames(alert_data) = c("id", "effect", "text", "trip_id")
  
  #Get the cancelled busses, these are the ones with no service
  cancelled_buses = alert_data %>% 
    filter(effect == "NO_SERVICE")
  #Then filter about by cancellation 
  cancelled_buses = cancelled_buses %>% 
    #In their text they say Cancellation, these means that the buses were cancelled.
    filter(grepl("Cancellation", text) == TRUE) %>% 
    #Now to join to our trip_updates GTFS, we just want the TRIP_ID and a column that says these TRIP_IDs were cancelled
    select(trip_id) %>% 
    mutate(cancelled = TRUE)
  
  #Now for the FULL DATASET, joining them all together (including the static files)
  bus_arrivals_full = trip_data %>% 
  left_join(stop_times %>% 
              select("trip_id", "stop_sequence", "arrival_time", "departure_time"), 
            by = c("trip_id" = "trip_id", "stop_sequence" = "stop_sequence")) %>%
  left_join(stops %>% select("stop_id", "stop_lat", "stop_lon"), 
            by = c("stop_id" = "stop_id")) %>%
  left_join(routes %>% select("route_id", "route_short_name"), 
            by = c("route_id" = "route_id")) %>% 
  left_join(cancelled_buses, 
            by = c("trip_id" = "trip_id"))
  
  #Return dataset
  return(bus_arrivals_full)
}



```

```{r}
#Getting information

#Currently we stored all the information as dates in our files - these have all the bus information
list_of_dates = c("27 March", "28 March", "29 March", "30 March", "31 March", "1 April", "2 April")

#Desired length is the length of our list (the number of days of information we got)
desired_length <- length(list_of_dates)

#Create a list that will store our dataframes of information
list_df <- vector(mode = "list", length = desired_length)

#For loop to go through each date                  
for(i in 1:length(list_of_dates)) {
  
  #Get the trip updates for a unique day
  trip_updates = read_json(paste("/Users/leonardophu/Desktop/2023/STATS 765/PROJECT/Temporary /", list_of_dates[i],"/Trip_Updates_", gsub(" ", "", list_of_dates[i]), ".json", sep = ""))
  #Get the alert information for a unique day
  alerts = read_json(paste("/Users/leonardophu/Desktop/2023/STATS 765/PROJECT/Temporary /", list_of_dates[i],"/Alert_Service_", gsub(" ", "", list_of_dates[i]), ".json", sep = ""))
  
  #use extract data to get the whole days worth of data
  daily_data = extract_data(trip_updates, alerts)
  
  #Store this to our list of information. Also we want to store the date this information was dealing with
  list_df[[i]]  = daily_data  %>%  mutate(date = paste(list_of_dates[i], "2023", sep = " "))
} 

#Combine all the list of dataframes we got into one BIG dataframe
full_dataset = do.call(rbind, list_df)
```

```{r}
#Cleaning the dataset

#Get the day of the week for a given day
full_dataset = full_dataset %>% mutate(day_of_week = wday(as.Date(date, format = "%d %B %Y"), label = TRUE))

#Some bits of dataset don't have both arrival and departure time. If we don't have both, we would assume they are the same. 
full_dataset$act_arrival_time = ifelse(is.na(full_dataset$act_arrival_time) == TRUE & is.na(full_dataset$act_departure_time) == FALSE, full_dataset$act_departure_time, full_dataset$act_arrival_time)
full_dataset$act_departure_time = ifelse(is.na(full_dataset$act_arrival_time) == FALSE & is.na(full_dataset$act_departure_time) == TRUE,  full_dataset$act_arrival_time, full_dataset$act_departure_time)

#Since these times are in total seconds from Jan 1970, we need to convert them to hours for a given day 
class(full_dataset$act_arrival_time) = c('POSIXt','POSIXct')
class(full_dataset$act_departure_time) = c('POSIXt','POSIXct')
```

```{r}
#Now we can extract different information. This here has information on buses THAT WASN'T CANCELLED
non_cancelled = subset(full_dataset, is.na(cancelled) == TRUE)
#The GTFS also has information on TRAINS. I just removed these from our dataset
non_cancelled = non_cancelled %>% filter(!(route_short_name %in% c("WEST", "NORTH","SOUTH", "EAST"))) %>%
  #Also filtered buses that don't have any arrival time (appears to be a error with their system)
  filter(is.na(act_arrival_time) == FALSE)

#For a given TIME, we want to bin our time to hours. E.g., 11:30 -> Is just 11. 9:45 -> Is just 9
non_cancelled$time_frame = as.factor(as.numeric(substr(non_cancelled$act_arrival_time, 12, 13)))

#Getting unique route names
#unique(non_cancelled$route_short_name)

#Getting the cancelled buses information 
cancelled_buses = subset(full_dataset, is.na(cancelled) == FALSE) %>% filter(!(route_short_name %in% c("WEST", "NORTH","SOUTH", "EAST"))) %>% group_by(route_short_name) %>% summarise(Tally = n()) 

#Get bus non cancellation rates. From our dataset it's about 20%
nrow(non_cancelled) / nrow(full_dataset)
```

```{r}
#Counts of total number of busses
total_buses = full_dataset %>% 
  filter(!(route_short_name %in% c("WEST", "NORTH","SOUTH", "EAST"))) %>% 
  group_by(route_short_name) %>% 
  summarise(total_counts = n()) %>% 
  filter(total_counts > 20)

#Cancelled bus proportion
cancelled_buses_proportion = cancelled_buses %>% 
  left_join(total_buses, by = "route_short_name") %>% 
  mutate(Cancelled_Proportion = Tally/total_counts) %>% 
  select(route_short_name, Cancelled_Proportion) %>% 
  arrange(desc(Cancelled_Proportion)) %>% 
  filter(is.na(route_short_name) != TRUE) %>% 
  #This is just to get the ordering we want in the barplot, can remove later on
  mutate(Position = factor(route_short_name, route_short_name))

print(cancelled_buses_proportion)

#Showing the cancelled bus proportion in a graph 
ggplot(cancelled_buses_proportion, aes(x = Position, y = Cancelled_Proportion)) + 
  geom_col() +
  theme_minimal()+
  coord_flip() + 
  theme(axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        panel.grid.major.y = element_blank(),
        plot.title = element_text(hjust = 0.5, face = "bold")) + 
  ylab("") +
  ggtitle("Proportion of bus cancellation")+ 
  xlab("Bus routes") +
  scale_y_continuous(expand = expansion(c(0,0.05)))

```

```{r}
#BUS CANCELLATION BY DAY 

#Getting the cancelled buses information 
cancelled_buses_day = subset(full_dataset, is.na(cancelled) == FALSE) %>% filter(!(route_short_name %in% c("WEST", "NORTH","SOUTH", "EAST"))) %>% group_by(day_of_week) %>% summarise(Tally = n()) 

total_buses_day = full_dataset %>% 
  filter(!(route_short_name %in% c("WEST", "NORTH","SOUTH", "EAST"))) %>% 
  group_by(day_of_week) %>% 
  summarise(total_counts = n()) 

#Cancelled bus proportion
cancelled_buses_day_proportion = cancelled_buses_day %>% 
  left_join(total_buses_day, by = "day_of_week") %>% 
  mutate(Cancelled_Proportion = Tally/total_counts) %>% 
  select(day_of_week, Cancelled_Proportion) %>% 
  arrange(desc(Cancelled_Proportion)) %>% 
  filter(is.na(day_of_week) != TRUE) %>% 
  #This is just to get the ordering we want in the barplot, can remove later on
  mutate(Position = factor(day_of_week, day_of_week))

#Showing the cancelled bus proportion in a graph 
ggplot(cancelled_buses_day_proportion, aes(x = Position, y = Cancelled_Proportion)) + 
  geom_col() +
  theme_minimal()+
  coord_flip() + 
  theme(axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        panel.grid.major.y = element_blank(),
        plot.title = element_text(hjust = 0.5, face = "bold")) + 
  ylab("") +
  ggtitle("Proportion of bus cancellation by day")+ 
  xlab("Day of week") +
  scale_y_continuous(expand = expansion(c(0,0.05)))
```


```{r}
library(ggplot2)

#We have a row of outliers

#We had one observation that was -75000 minutes. Really skeptical so this was removed 
ggplot(non_cancelled %>% filter(delay > -75000), mapping = aes(x = day_of_week, y = delay)) + geom_boxplot()

ggplot(non_cancelled %>% filter(delay > -75000), mapping = aes(x = day_of_week, y = delay)) + geom_boxplot() + xlab("Day of week")

ggplot(non_cancelled %>% filter(delay > -75000 & time_frame %in% c(21,22,23)), mapping = aes(x = time_frame, y = delay)) + geom_boxplot() + xlab("Hour of the day")
```


















